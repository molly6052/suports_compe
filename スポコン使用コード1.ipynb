{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"FyMuu3cgSlTw"},"source":["# detectron2\n","\n","審判も含めたマスクを作る"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9dipu4d8TPRN"},"source":["install detectron2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29656,"status":"ok","timestamp":1672745095641,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"lta13w8OSpe7","outputId":"c3f5a99e-f084-45d6-ad21-89490589c043"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[K     |████████████████████████████████| 274 kB 31.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp38-cp38-linux_x86_64.whl size=44089 sha256=edfc42b8482e86136b7a90e3218c862ebecfe29484ead5ddcfd9d88da60cdbed\n","  Stored in directory: /root/.cache/pip/wheels/52/dd/2b/10ff8b0ac81b93946bb5fb9e6749bae2dac246506c8774e6cf\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dask 2022.2.1 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\u001b[0m\n","Successfully installed pyyaml-5.1\n","Cloning into 'detectron2'...\n","remote: Enumerating objects: 14718, done.\u001b[K\n","remote: Total 14718 (delta 0), reused 0 (delta 0), pack-reused 14718\u001b[K\n","Receiving objects: 100% (14718/14718), 5.98 MiB | 14.79 MiB/s, done.\n","Resolving deltas: 100% (10668/10668), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.8/dist-packages (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.8/dist-packages (2.0.6)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (2.1.1)\n","Collecting yacs>=0.1.8\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (0.8.10)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (1.5.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.8/dist-packages (4.64.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n","Collecting fvcore<0.1.6,>=0.1.5\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n","\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Collecting omegaconf>=2.1\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.0 MB/s \n","\u001b[?25hCollecting hydra-core>=1.1\n","  Downloading hydra_core-1.3.1-py3-none-any.whl (154 kB)\n","\u001b[K     |████████████████████████████████| 154 kB 64.7 MB/s \n","\u001b[?25hCollecting black\n","  Downloading black-22.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 67.3 MB/s \n","\u001b[?25hCollecting timm\n","  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[K     |████████████████████████████████| 549 kB 64.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0.2) (1.21.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs>=0.1.8) (5.1)\n","Collecting portalocker\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 77.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1) (5.10.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (57.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.15.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.23.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (5.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n","Collecting click>=8.0.0\n","  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n","\u001b[K     |████████████████████████████████| 96 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black) (4.4.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black) (2.0.1)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black) (2.6.0)\n","Collecting mypy-extensions>=0.4.3\n","  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n","Collecting pathspec>=0.9.0\n","  Downloading pathspec-0.10.3-py3-none-any.whl (29 kB)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 75.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.8.2)\n","Building wheels for collected packages: fvcore, antlr4-python3-runtime\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=156f05b280cefd901791288987654f51ab5e0bf4f2e103f7fc3fa4dad812e73c\n","  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=f69f240b7a75a76a689d9c5a8e9e0e95da7d87b16f8fefe1934406152a3822c2\n","  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n","Successfully built fvcore antlr4-python3-runtime\n","Installing collected packages: portalocker, antlr4-python3-runtime, yacs, pathspec, omegaconf, mypy-extensions, iopath, huggingface-hub, click, timm, hydra-core, fvcore, black\n","  Attempting uninstall: click\n","    Found existing installation: click 7.1.2\n","    Uninstalling click-7.1.2:\n","      Successfully uninstalled click-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n","Successfully installed antlr4-python3-runtime-4.9.3 black-22.12.0 click-8.1.3 fvcore-0.1.5.post20221221 huggingface-hub-0.11.1 hydra-core-1.3.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.3.0 pathspec-0.10.3 portalocker-2.6.0 timm-0.6.12 yacs-0.1.8\n"]}],"source":["!python -m pip install pyyaml==5.1\n","import sys, os, distutils.core\n","# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n","# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n","!git clone 'https://github.com/facebookresearch/detectron2'\n","dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","sys.path.insert(0, os.path.abspath('./detectron2'))\n","\n","# Properly install detectron2. (Please do not install twice in both ways)\n","# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1672745095642,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"8jry6YsNTAXB","outputId":"4e3f30f3-b2dc-4ba2-b9c8-18db942020ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Sun_Feb_14_21:12:58_PST_2021\n","Cuda compilation tools, release 11.2, V11.2.152\n","Build cuda_11.2.r11.2/compiler.29618528_0\n","torch:  1.13 ; cuda:  cu116\n","detectron2: 0.6\n"]}],"source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sm2HVLWMTF9o"},"outputs":[],"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HyOK671aTL0H"},"source":["柔道動画からファーストフレームを読み込む"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ktzxrFtTZbd"},"outputs":[],"source":["filepath = '/content/drive/MyDrive/Colab Notebooks/2018WCB_60_P2_SELLO Edwin_BOT_NAZIR BIN Abdou_MAD.mp4'\n","cap = cv2.VideoCapture(filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1672745139729,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"23-zRkQQTb9v","outputId":"a234ae4a-bddd-4a78-e494-deb642a20896"},"outputs":[{"name":"stdout","output_type":"stream","text":["size: (720, 1280), fps: 25\n"]}],"source":["width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","print(f\"size: ({height}, {width}), fps: {fps}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bqKLXtWQTe7E"},"source":["VideoCaptureからフレームを取得する"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zUW4cHBgTd2o"},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","import math\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":7222,"status":"ok","timestamp":1672745154339,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"MnTeKY-8Tkua","outputId":"7f09e246-f570-4255-fd51-08e71cf3e979"},"outputs":[],"source":["cap = cv2.VideoCapture(filepath)\n","#指定したフレームをセットする ： ０が最初のフレーム\n","first_frame = 900\n","cap.set(cv2.CAP_PROP_POS_FRAMES, first_frame)\n","#read()でフレームを一枚読み込む\n","ret, image = cap.read()\n","if not ret:\n","  print('noimage')\n","else:\n","  cv2_imshow(image)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PcCTN-sKTpwX"},"source":["フレームの上と下を黒埋めする"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":3425,"status":"ok","timestamp":1672745163822,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"Do8z19ZEUI5W","outputId":"e789b8dd-63d6-4a2d-a74a-9d45a469819c"},"outputs":[],"source":["image_test = image.copy()\n","image_test[0:250,:] = 0\n","image_test[600:,:] = 0\n","cv2_imshow(image_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ASEwm3BFUPCj"},"source":["detectron2の学習済みモデルを適用させる"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19918,"status":"ok","timestamp":1672745280477,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"FvDOpjpRULkK","outputId":"267fc25a-be26-46a0-8869-766bfdbe1a79"},"outputs":[{"name":"stdout","output_type":"stream","text":["[01/03 11:27:45 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x/137259246/model_final_9243eb.pkl ...\n"]},{"name":"stderr","output_type":"stream","text":["model_final_9243eb.pkl: 144MB [00:14, 10.1MB/s]                           \n"]}],"source":["cfg = get_cfg()\n","# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.95  # set threshold for this model\n","# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml\")\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6982,"status":"ok","timestamp":1672745292736,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"TyYI1eaPUUU1","outputId":"72030bd1-eacc-4127-c501-86260abff4e3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]}],"source":["outputs = predictor(image_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1672745304729,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"AiFGyETxUfVD","outputId":"ac1d25f1-dbf3-4fa6-b698-d7b4b87416e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0, 0, 0], device='cuda:0')\n","Boxes(tensor([[1057.5852,  277.9212, 1180.8945,  490.4292],\n","        [  82.7005,  274.1915,  201.1749,  483.4684],\n","        [ 597.5090,  291.9864,  655.2814,  472.6474]], device='cuda:0'))\n"]}],"source":["# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n","print(outputs[\"instances\"].pred_classes)\n","print(outputs[\"instances\"].pred_boxes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":4986,"status":"ok","timestamp":1672745329647,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"znf5UfmnUhTr","outputId":"74edc40a-99d6-49de-8cd8-74dafebb15ed"},"outputs":[],"source":["# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(image_test[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=2.0)\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(out.get_image()[:, :, ::-1])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Dn6fdskbUkhD"},"source":["選手のセグメントを取り出して、マスクを作成"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZX7DvRn_Uiqk"},"outputs":[],"source":["# このclasses_listのindexと物体のカテゴリーIDが対応しています\n","classes_list= MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes\n","\n","objects = []\n","for id in outputs[\"instances\"]._fields[\"pred_classes\"].cpu().numpy():\n","  obj = classes_list[id]\n","  objects.append(obj)\n","# 推定した物体名のリスト\n","object_est = [(k,i) for k,i in zip(objects,outputs[\"instances\"]._fields[\"scores\"].cpu().numpy())]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":8532,"status":"ok","timestamp":1672745417794,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"4MTaUOudUqwi","outputId":"e2419090-fd10-4e68-ef5b-97a48d7770a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","RGB\n"]},{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGB size=1280x720 at 0x7FEABC68C070>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","RGB\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABQAAAALQCAIAAABAH0oBAAAOlElEQVR4nO3dzW7bMBCF0abIg+vRu0iBtq5j64cUybnnbAMoo+WHoegfPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOM+Rg9Ad9u2nf4rAABAGQK4lNM1K4MBAIDyfo4egGauRKwABgAAyhPA/KaBAQCA2gRwEU3yVQMDAACFCWD+oYEBAICqBHAFqhUAAOAtAcwjOQ0AAJQkgJenVwEAAPYQwAAAAEQQwAAAAEQQwAAAAEQQwAAAAEQQwGtzAxYAAMBOAhgAAIAIAhgAAIAIAhgAAIAIAnhhPgAGAADYTwADAAAQQQADAAAQQQADAAAQQQCvygfAAAAAhwhgAAAAIgjgJVn/AgAAHCWA16N+AQAAThDAi1G/AAAA5wjglahfAACA0wTwMu6sX6UNAADU8zl6AN6TowAAANcJ4KlJXwAAgFYE8KSkLwAAQFsCeDrSFwAAoAcBPBHpCwAA0I9boGehfgEAALoSwFNQvwAAAL0J4PHULwAAwA0E8GDqFwAA4B4CmOeUOQAAUIwABgAAIIIAHmnyLevk4wEAABwigAEAAIgggAEAAIgggHnFKWgAAKAMATyMtgQAALiTAAYAACCCAOYNm2oAAKAGAQwAAEAEAQwAAEAEATyGc8UAAAA3E8C8J9cBAIACBDAAAAARBDAAAAARBDAAAAARBDAAAAARBDAAAAARBDAAAAARBDAAAAARBPAAK/6s7oozAwAA/E0AAwAAEEEAAwAAEEEAAwAAEEEAAwAAEEEAAwAAEEEAAwAAEEEAAwAAEEEAAwAAEEEAs9e2baNHAAAAOE8AAwAAEEEA380eFQAAYAgBDAAAQAQBzAHW1wAAwLoEMMdoYAAAYFEC+FbqEQAAYBQBzGEyHgAAWJEA5gwNDAAALEcA30c0AgAADCSAOUnPAwAAaxHAN5GLAAAAYwlgAAAAIgjgO1Rd/1Z9LwAAoCQBDAAAQAQBDAAAQAQB3F3tc8K13w4AAKhEAAMAABBBAAMAABBBAAMAABBBAHOVz4ABAIAlCGAAAAAiCGAasAQGAADmJ4ABAACIIIBpwxIYAACYnACmGQ0MAADMTACnU60AAEAIARztq34bNrCcBgAApiWAc/0dqxoYAAAoTwD3NW0N/j/YtKMCAAA0IYATaV0AACCQAOaPVmEssAEAgAkJYNoTwAAAwIQEcF/LpeByAwMAAOwkgONIXAAAIJMA5pFCBgAAShLAPHGlgfUzAAAwJwHMc9u2SVkAAKASAcwrMhgAAChDAPPe/gxWywAAwLQ+Rw/AMr7i9mni6l4AAGB+AphjtC4AALAoR6ABAACIIIABAACIIIC7c2YYAABgBgIYAACACAIYAACACAIYAACACAIYAACACAI4jku5AACATAIYAACACAIYAACACAIYAACACAIYAACACAI4kXuwAACAQAIYAACACAIYAACACAIYAACACAIYAACACAI4lHuwAACANAIYAACACAIYAACACAIYAACACAIYAACACAIYAACACAIYAACACAI4l19CAgAAoghgAAAAIghgAAAAIghgAAAAIghgAAAAIghgAAAAIgjg7ly2DAAAMAMBHE2cAwAAOQQwAAAAEQQwAAAAEQQwAAAAEQQwAAAAEQQwAAAAEQRwX65ZBgAAmIQABgAAIIIATmdHDQAAhBDAAAAARBDAAAAARBDAHTldDAAAMA8BDAAAQAQBDAAAQAQBDAAAQAQB3IsPgAEAAKYigAEAAIgggAEAAIgggHFaGwAAiCCAu5CUAAAAsxHAAAAARBDA7Vn/AgAATEgAN6Z+AQAA5iSAW2pbv9u2yWkAAIBWBHAznWJVBgMAADTxMXqAIpo36tMHdi1hmQ0AANQmgBu4p367/sdOzwQAAJiHI9BXDelGsQoAAHCUAL7EJhYAAGAVAvi8saWqkwEAAA4RwCf1u/O5x2MBAAAQwAAAAEQQwGdMsv61LgYAANhPAB9WNTurvhcAAMAXAQwAAEAEAXxMvzXpuSdb2wIAAOwkgA9QmwAAAOsSwHt1rV9pDQAA0JsA3kX9AgAArE4Av6d+AQAAChDAb8wfqA0nnP9lAQAAThPAr/QOQsEJAABwGwH8LfULAABQiQB+Tp0CAAAUI4ArkOsAAABvCeAnbuhJyQoAAHAzAQwAAEAEATxAj/Vvq2daTQMAAFUJYAAAACIIYAAAACIIYAAAACII4Dp8vgsAAPCCAL6bTAUAABhCAAMAABBBAAMAABBBAJfifDUAAMB3BPCtBCoAAMAoAhgAAIAIAvg+96x/LZkBAACeEsA8ktAAAEBJAviJHgWoKgEAAMb6HD1AcUO6d9s2vQ0AAPBAAHehPwEAAGYjgFvSvQAAANP6GD3AvA7V7ITpe3qkCd8FAADgOpdgXTXtB7fnpprzXQAAAK6zAX7luxpcqBKPjrrQqwEAABwigOvb37TqFwAAKEwAR3hbttIXAAAoTwAneshd9QsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHDRL9g8G708bUiqAAAAAElFTkSuQmCC","text/plain":["<PIL.Image.Image image mode=RGB size=1280x720 at 0x7FEA94F3D520>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(720, 1280, 3)\n","RGB\n"]},{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGB size=1280x720 at 0x7FEB3A827280>"]},"metadata":{},"output_type":"display_data"}],"source":["object_estimation = object_est\n","dct = {\"firstframe\":object_estimation}\n","# ビットマップの抽出\n","bool_array = outputs[\"instances\"]._fields[\"pred_masks\"]\n","a = 0\n","for j,b_array in enumerate(bool_array):\n","    # tensorをnumpy配列に変換\n","    array = b_array.cpu().numpy()\n","    # 論理値の反転\n","    inv_bool_array = []\n","    inv1_bool_array = []\n","    for l in array:\n","      inv_b = []\n","      inv_a = []\n","      for b in l:\n","        if b == False:\n","          inv_b.append(True)\n","          inv_a.append(False)\n","        else:\n","          inv_b.append(False)\n","          inv_a.append(True)\n","      inv_bool_array.append(inv_b)\n","      inv1_bool_array.append(inv_a)\n","    # cv2オブジェクトはnumpy配列なので,正(true)を灰色に変換\n","    copy_img = image_test.copy()\n","\n","    copy_img[inv_bool_array] = [0,0,0]\n","    copy_img[inv1_bool_array] = [128,128,128]\n","    print(copy_img.shape)\n","    ## 画像の保存\n","    a +=1\n","    cv2.imwrite(f'/content/drive/MyDrive/Colab Notebooks/zyudou_firstframe_{a}.png', copy_img[:, :, ::-1])\n","    img = Image.open(f\"/content/drive/MyDrive/Colab Notebooks/zyudou_firstframe_{a}.png\")\n","    print(img.mode)\n","    cv2_imshow(copy_img[:, :, ::-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1672745480398,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"Uopd9eWJUvnk","outputId":"b40b3ffb-4ac9-4897-8fee-b5c066739bec"},"outputs":[{"name":"stdout","output_type":"stream","text":["RGB\n"]}],"source":["from PIL import Image\n","img = Image.open(\"/content/drive/MyDrive/Colab Notebooks/zyudou_firstframe_1.png\")\n","print(img.mode)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZMvBLrS-UxGW"},"source":["# XMemを適用する"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1672745484599,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"GT73h-l3U01F","outputId":"b4ec916c-388c-4935-b4c5-b9ed94c1f15c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Jan  3 11:31:24 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P0    31W /  70W |   4232MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n","Using GPU\n"]}],"source":["!nvidia-smi\n","\n","import torch\n","\n","if torch.cuda.is_available():\n","  print('Using GPU')\n","  device = 'cuda'\n","else:\n","  print('CUDA not available. Please connect to a GPU instance if possible.')\n","  device = 'cpu'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wOoP_ufSU4vs"},"source":["## 必要なパッケージをインストールする"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1672745569660,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"wu1IaEDSZ6Gn","outputId":"3a473387-500e-4885-d545-09860611cd97"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.cuda.empty_cache()\n","\n","import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":24192,"status":"ok","timestamp":1672745599941,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"bjHM6fCcU8b0","outputId":"adc495d0-ba8d-422b-a93d-4f5a994bf112"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'XMem'...\n","remote: Enumerating objects: 473, done.\u001b[K\n","remote: Counting objects: 100% (176/176), done.\u001b[K\n","remote: Compressing objects: 100% (48/48), done.\u001b[K\n","remote: Total 473 (delta 133), reused 128 (delta 128), pack-reused 297\u001b[K\n","Receiving objects: 100% (473/473), 238.74 KiB | 19.89 MiB/s, done.\n","Resolving deltas: 100% (258/258), done.\n","/content/XMem\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n","Collecting numpy\n","  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 34.4 MB/s \n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\n","Successfully installed numpy-1.24.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/cheind/py-thin-plate-spline (from -r requirements.txt (line 4))\n","  Cloning https://github.com/cheind/py-thin-plate-spline to /tmp/pip-req-build-ilzo0s38\n","  Running command git clone -q https://github.com/cheind/py-thin-plate-spline /tmp/pip-req-build-ilzo0s38\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (3.38.0)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (4.4.0)\n","Collecting gitpython\n","  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n","\u001b[K     |████████████████████████████████| 184 kB 34.7 MB/s \n","\u001b[?25hCollecting hickle\n","  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n","\u001b[K     |████████████████████████████████| 107 kB 81.9 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (2.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (1.24.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from thinplate==1.0.0->-r requirements.txt (line 4)) (1.13.0+cu116)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from thinplate==1.0.0->-r requirements.txt (line 4)) (0.14.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4)) (4.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (2.23.0)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from progressbar2->-r requirements.txt (line 1)) (3.4.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from progressbar2->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 2)) (3.8.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 2)) (4.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 2)) (4.64.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle->-r requirements.txt (line 5)) (3.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.4.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.19.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.51.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.15.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.38.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 6)) (5.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 6)) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (2022.12.7)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (1.7.1)\n","Building wheels for collected packages: thinplate\n","  Building wheel for thinplate (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for thinplate: filename=thinplate-1.0.0-py3-none-any.whl size=6723 sha256=58378c8f4dd6234a19e188cafd8ef40e75b34b525cb1737f35fbc7f64264f20d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-af3wv_co/wheels/6f/e1/9f/aba4f30d4acad9b93834d7f0b520a61d49996f23703f78a058\n","Successfully built thinplate\n","Installing collected packages: smmap, gitdb, thinplate, hickle, gitpython\n","Successfully installed gitdb-4.0.10 gitpython-3.1.30 hickle-5.0.2 smmap-5.0.0 thinplate-1.0.0\n"]}],"source":["!git clone https://github.com/hkchengrex/XMem.git\n","%cd XMem\n","!pip install opencv-python\n","!pip install -U numpy\n","!pip install -r requirements.txt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mQeLCF5oVBoH"},"source":["XMemの事前学習モデルをダウンロードする"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46008,"status":"ok","timestamp":1672745656797,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"W0SY0Ai9U-wQ","outputId":"cc48020b-9d51-40fe-9161-1d7420ddebb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-01-03 11:33:30--  https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511262077/ea2968ee-04ab-4dee-8596-03319e8c7e9f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230103T113331Z&X-Amz-Expires=300&X-Amz-Signature=267305df4211610bb2f90ff2a9e944e05776eb43637886c3e20b193d2aac9e27&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511262077&response-content-disposition=attachment%3B%20filename%3DXMem.pth&response-content-type=application%2Foctet-stream [following]\n","--2023-01-03 11:33:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511262077/ea2968ee-04ab-4dee-8596-03319e8c7e9f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230103T113331Z&X-Amz-Expires=300&X-Amz-Signature=267305df4211610bb2f90ff2a9e944e05776eb43637886c3e20b193d2aac9e27&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511262077&response-content-disposition=attachment%3B%20filename%3DXMem.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 249026057 (237M) [application/octet-stream]\n","Saving to: ‘./saves/XMem.pth’\n","\n","XMem.pth            100%[===================>] 237.49M  1.79MB/s    in 45s     \n","\n","2023-01-03 11:34:16 (5.33 MB/s) - ‘./saves/XMem.pth’ saved [249026057/249026057]\n","\n"]}],"source":["!wget -P ./saves/ https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TjOiSroWVKbK"},"source":["必要なライブラリをインポート"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["8c02b95270c6439e93fa7f93d2529ffc","ea7ce65c188943b68b9222cfd7d0e72e","b8079930999d42149ad0b4d8edb1bd91","a7987ef514fe45369c8a4cc337f806de","7a9a22f52e4945df993939d9a13b9041","a63ea28cb6464b238ae17ba0fed1dc17","73df60f8ae3743718af74ba973061989","2a1a655909cc4a36963c456cecf29f5d","ac1cb3213b3a4eaebc51e24840060763","555dd134b00840368d6374268c3eef88","fa94f3b681204b4f859ddc396bbaec29","bbc34145149b4b829bc801076a220807","6ef206b5a92c4bf0a4b263cb4eafb0b3","20c25c0d9ea742cba04b77200fb48406","a981a179460943c89e37b507d6178b2b","2cffbaab186f467eb03c8018bd327aad","fd82cbf2b4344063aaa17661cae0179b","a0c6fd41a9b147dfa3fe3e8cb407dd84","0222a5a62fa7476ca2fd5d5be361ac1d","8a6d63f236bf4ff382608dc3a0019e83","ad5253e3164745dbb4c4a09584a69c8d","de928ca77c6d422f91bc814116763279"]},"executionInfo":{"elapsed":2999,"status":"ok","timestamp":1672745662002,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"xHMHQLrPVNCm","outputId":"082271b4-4965-4b9b-df65-dff905269fe7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n","Single object mode: False\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c02b95270c6439e93fa7f93d2529ffc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbc34145149b4b829bc801076a220807","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","from os import path\n","from argparse import ArgumentParser\n","import shutil\n","\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from PIL import Image\n","\n","from inference.data.test_datasets import LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n","from inference.data.mask_mapper import MaskMapper\n","from model.network import XMem\n","from inference.inference_core import InferenceCore\n","\n","from progressbar import progressbar\n","\n","torch.set_grad_enabled(False)\n","\n","# default configuration\n","config = {\n","    'top_k': 20,\n","    'mem_every': 4,\n","    'deep_update_every': -1,\n","    'enable_long_term': True,\n","    'enable_long_term_count_usage': True,\n","    'num_prototypes': 128,\n","    'min_mid_term_frames': 5,\n","    'max_mid_term_frames': 10,\n","    'max_long_term_elements': 10000,\n","}\n","\n","network = XMem(config, './saves/XMem.pth').eval().to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-mKKSNnFVQXp"},"source":["データを準備する（first_frameとvideo）"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhRfJXsxVUag"},"outputs":[],"source":["video_name = '/content/drive/MyDrive/Colab Notebooks/2018WCB_60_P2_SELLO Edwin_BOT_NAZIR BIN Abdou_MAD.mp4'\n","mask_name_1 = \"/content/drive/MyDrive/Colab Notebooks/zyudou_firstframe_1.png\"\n","mask_name_2 = \"/content/drive/MyDrive/Colab Notebooks/zyudou_firstframe_2.png\"\n","mask_name_3 = \"/content/drive/MyDrive/Colab Notebooks/zyudou_firstframe_3.png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQo6tTFdVXKC"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from IPython.display import display, Image\n","\n","\n","def imshow(img):\n","    \"\"\"ndarray 配列をインラインで Notebook 上に表示する。\n","    \"\"\"\n","    ret, encoded = cv2.imencode(\".png\", img)\n","    display(Image(encoded))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1672745677880,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"x8eVxfGRVYSL","outputId":"43e5a1bd-9453-4eaf-ead2-9243692f8072"},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 1280)\n","[  0 255]\n"]},{"data":{"image/png":"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","text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"output_type":"display_data"}],"source":["# 画像を読み込む。\n","img_1 = cv2.imread(mask_name_1)\n","img_2 = cv2.imread(mask_name_2)\n","img_3 = cv2.imread(mask_name_3)\n","img = img_1 + img_2 + img_3\n","# img = cv2.resize(img , (int(width *2), int(height *2)))\n","# , interpolation=cv2.INTER_LINEAR\n","# グレースケール形式に変換する。\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","# 2値化する。\n","ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n","print(binary.shape)\n","print(np.unique(binary))\n","imshow(binary)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1672745696729,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"hlY9EbZ3Va64","outputId":"b6f004ee-1bdb-4c9b-8101-2b6a84c16ef1"},"outputs":[{"name":"stdout","output_type":"stream","text":["L\n"]}],"source":["from PIL import Image\n","pil_img = Image.fromarray(binary)\n","print(pil_img.mode)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"orYiV02_Vkse"},"source":["個別のマスクを作成する"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ltLtUQKVjT4"},"outputs":[],"source":["import numpy as np\n","from scipy.ndimage import measurements, morphology, find_objects\n","\n","def remove_noise(mask, threshold=3000):\n","    labels_bi, nbr_objects_bi = measurements.label(mask) # 普通にセグメントをカウント\n","    open_img = morphology.binary_opening(mask, iterations=1) # ノイズ除去（iterationsが大きいと大きい領域が除去される）\n","    labels_op, nbr_objects_op = measurements.label(open_img)\n","    areas = np.array(measurements.sum(open_img, labels_op, np.arange(labels_op.max()+1)))\n","    mask_noise = areas > threshold\n","    result_mask = mask_noise[labels_op] # ノイズ除去したマスク\n","    labeled_img, nbr_objects_rsg = measurements.label(result_mask)\n","    #print(\"Number of objects:\", nbr_objects_rsg)\n","    return result_mask, labeled_img, nbr_objects_rsg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_S8gOjrVrdR"},"outputs":[],"source":["def culculate_xcom(mask, nbr_objects_rsg):\n","    #重心\n","    point = measurements.center_of_mass(mask, labeled_img,range(1, nbr_objects_rsg + 1))\n","    # plt.figure(figsize=(5,5))\n","    # plt.subplot(111)\n","    # plt.plot(np.array(point)[:,1],np.array(point)[:,0],'ro',ms=4)\n","    # [plt.text(np.array(point)[i,1]+5,np.array(point)[i,0]-20,i, fontsize=12) for i in range(len(point))]\n","    # plt.imshow(labeled_img, cmap=plt.cm.viridis)\n","    # plt.show()\n","    x_com = [coord[1] for coord in point] # x座標だけ取り出す\n","    print('x座標重心: ', x_com)\n","    return x_com\n","\n","def get_object_mask(id, labeled_img):\n","    # idマスクのみを取得\n","    slice_x, slice_y = find_objects(labeled_img==id)[0]\n","    roi = labeled_img[slice_x, slice_y]\n","    # np.full(shape, 値)：値で埋められたshapeのnp.arrayができる\n","    mask_compare = np.full(np.shape(labeled_img), id) # idだけのマスクを作成\n","\n","    # np.equal(配列1, 配列2)：配列1と配列2を比較し、要素ごとの比較結果を返す(True or False)\n","    separate_mask_index1 = np.equal(labeled_img, mask_compare).astype(int).copy()\n","    separate_mask_index2 = np.equal(labeled_img, mask_compare).astype(int).copy()\n","    separate_mask_index3 = np.equal(labeled_img, mask_compare).astype(int).copy()\n","\n","    # マスクがTrue(=1)の場所は1(加算して2にするため)に置き換える（パレット = ラートidx: 1, 人物: idx2）\n","    separate_mask_index1[separate_mask_index1 == 1] = 1 # 画像として表示したい場合は255で置き換える\n","    separate_mask_index2[separate_mask_index2 == 1] = 2\n","    separate_mask_index3[separate_mask_index3 == 1] = 3\n","\n","    separate_mask_index1 = np.uint8(separate_mask_index1) # セグメント用に変換\n","    separate_mask_index2 = np.uint8(separate_mask_index2) # セグメント用に変換\n","    separate_mask_index3 = np.uint8(separate_mask_index3) # セグメント用に変換\n","\n","    # plt.imshow(separate_mask)\n","    # plt.show()\n","    # plt.imshow(roi)\n","    return [separate_mask_index1, separate_mask_index2, separate_mask_index3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1672745704589,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"5TZ1Uaj_Vs1E","outputId":"1d884963-597d-4b00-c27a-a94b66bba4eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["x座標重心:  [148.16374908825674, 1113.817784835252, 625.2998438313379]\n","[0 1]\n","[0 2]\n","[0 3]\n","人物1 id: 1, 人物2 id: 2, 人物3 id: 3\n","[0 1 2 3]\n"]}],"source":["mask_denoise, labeled_img, nbr_objects_rsg = remove_noise(binary, threshold=3000)\n","x_com = culculate_xcom(mask_denoise, nbr_objects_rsg)\n","\n","# ラートマスクを取得（argmin）\n","person1_id = np.argmin(x_com) +1 # 背景に使われるマスクid=0を考慮して、+1している（dtype=int32）\n","person1_separate_mask = get_object_mask(person1_id, labeled_img)[0]\n","\n","# 人物マスクを取得（argmax）\n","person2_id = np.argmax(x_com) +1\n","person2_separate_mask = get_object_mask(person2_id, labeled_img)[1]\n","\n","# 人物マスクを取得（argmax）\n","person3_id = np.argmax(x_com) +2\n","person3_separate_mask = get_object_mask(person3_id, labeled_img)[2]\n","print(np.unique(person1_separate_mask))\n","print(np.unique(person2_separate_mask))\n","print(np.unique(person3_separate_mask))\n","\n","print(f\"人物1 id: {person1_id}, 人物2 id: {person2_id}, 人物3 id: {person3_id}\")\n","print(np.unique(person1_separate_mask + person2_separate_mask + person3_separate_mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3fhfzcZY16S"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","def create_idxc_image(separate_mask_1,separate_mask_2,separate_mask_3):\n","    pil_img_1 = Image.fromarray(separate_mask_1).convert('P')\n","    pil_img_2 = Image.fromarray(separate_mask_2).convert('P')\n","    pil_img_3 = Image.fromarray(separate_mask_3).convert('P')\n","\n","    # ここではid=1: 緑, id=2: 赤とする（id=0: 黒=背景）\n","    palette_1 = [0,0,0] + [0, 128, 0] + [128, 0, 0] + [0,0,0] * 253 # [26,237,160]\n","    palette_2 = [0,0,0] + [240, 0, 0] + [0, 128, 0] + [0,0,0] * 253 # [26,237,160]\n","    palette_3 = [0,0,0] + [240, 0, 0] + [0, 0, 128] + [0,0,0] * 253 # [26,237,160]\n","\n","    pil_img_1.putpalette(palette_1)\n","    pil_img_2.putpalette(palette_2)\n","    pil_img_3.putpalette(palette_3)\n","\n","    return [pil_img_1, pil_img_2, pil_img_3]\n","\n","def convert_np(pil_im):\n","    # Convert Image to RGB and make into Numpy array\n","    na = np.array(pil_im.convert('RGB'))\n","    # Get used colours and counts of each\n","    colours, counts = np.unique(na.reshape(-1,3), axis=0, return_counts=1)\n","    #print(f\"色: \\n{colours},\\n 数: \\n{counts}\")\n","    return na"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga06a4RaZbvb"},"outputs":[],"source":["# ラートセグメントの取得\n","person1_cp_img = create_idxc_image(person1_separate_mask, person2_separate_mask, person3_separate_mask)[0]\n","person2_cp_img = create_idxc_image(person1_separate_mask, person2_separate_mask, person3_separate_mask)[1]\n","person3_cp_img = create_idxc_image(person1_separate_mask, person2_separate_mask, person3_separate_mask)[2]\n","person1_np = convert_np(person1_cp_img)\n","person2_np = convert_np(person2_cp_img)\n","person3_np = convert_np(person3_cp_img)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JP3zS7DJdF-g"},"source":["XMemを適応"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZLYfk8agdKrY"},"source":["選手1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1672745724554,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"M_P2b6lIc_K7","outputId":"e10c751e-fef0-4343-ff65-bc46d8c11a88"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 2 3]\n","(720, 1280)\n"]}],"source":["mask_white = np.array(person1_cp_img)\n","mask_blue = np.array(person2_cp_img)\n","mask_person = np.array(person3_cp_img)\n","mask = mask_blue + mask_white + mask_person\n","print(np.unique(mask))\n","print(mask.shape)\n","num_objects = len(np.unique(mask)) - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1672745791225,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"b2-MvUlVlKa2","outputId":"dd1f143e-0d85-4cac-b704-3e5b78bdce93"},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=L size=1280x720 at 0x7FEA94D8AA00>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=L size=1280x720 at 0x7FEA958A64C0>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=L size=1280x720 at 0x7FEA94D8AA00>"]},"metadata":{},"output_type":"display_data"}],"source":["cv2_imshow(mask_white*255)\n","cv2_imshow(mask_blue*255)\n","cv2_imshow(mask_person*255)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gw4wEz4xdeoC"},"outputs":[],"source":["height = mask.shape[0]\n","width = mask.shape[1]\n","#mask = cv2.resize(mask , (int(width*0.5), int(height*0.5)), interpolation=cv2.INTER_LINEAR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0Yccfjvd7f8"},"outputs":[],"source":["allperson_segment_output = \"/content/drive/MyDrive/Colab Notebooks/sports_compe/all_segment.mp4\"\n","person1_mask_output = \"/content/drive/MyDrive/Colab Notebooks/sports_compe/white_mask.mp4\"\n","person2_mask_output = \"/content/drive/MyDrive/Colab Notebooks/sports_compe/blue_mask.mp4\"\n","person3_mask_output = \"/content/drive/MyDrive/Colab Notebooks/sports_compe/referee_mask.mp4\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zw0-V5OGdkV8"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","import os\n","from inference.interact.interactive_utils import image_to_torch, index_numpy_to_one_hot_torch, torch_prob_to_numpy_mask, overlay_davis\n","import IPython\n","# xmem_fn\n","first_frame = 900\n","cap = cv2.VideoCapture(video_name)\n","cap.set(cv2.CAP_PROP_POS_AVI_RATIO, first_frame)\n","total_frame = cap.get(cv2.CAP_PROP_POS_FRAMES) - first_frame\n","print(\"total frames: \", total_frame)\n","cap.set(cv2.CAP_PROP_POS_AVI_RATIO, first_frame)\n","\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","fmt = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n","\n","segment_writer = cv2.VideoWriter(allperson_segment_output, fmt, fps, (width, height)) # セグメント動画用\n","person1_mask_writer = cv2.VideoWriter(person1_mask_output, fmt, fps, (width, height)) # マスク動画用\n","person2_mask_writer = cv2.VideoWriter(person2_mask_output, fmt, fps, (width, height)) # マスク動画用\n","person3_mask_writer = cv2.VideoWriter(person3_mask_output, fmt, fps, (width, height)) # マスク動画用\n","\n","# 元動画をそのまま貼り付けるための設定\n","#########################################################\n","c = 0\n","while (cap.isOpened()):\n","  _, frame = cap.read()\n","\n","  if frame is None or c == first_frame:\n","    break\n","  # オプティカルフロー動画のflowマスク取得位置以前は元動画をそのまま\n","  if c < first_frame:\n","    segment_writer.write(frame)\n","    person1_mask_writer.write(frame)\n","    person2_mask_writer.write(frame)\n","    person3_mask_writer.write(frame)\n","  c += 1\n","#########################################################\n","\n","# セグメントとマスク動画を保存\n","torch.cuda.empty_cache()\n","processor = InferenceCore(network, config=config)\n","processor.set_all_labels(range(1, num_objects+1)) # consecutive labels\n","\n","cap.set(cv2.CAP_PROP_POS_FRAMES, first_frame) # 人物のマスクを取り出したフレームNo. からスタート\n","\n","# You can change this number\n","frames_to_propagate = total_frame\n","# 何倍速で動画にするか\n","visualize_every = 1\n","current_frame_index = 0\n","\n","\n","with torch.cuda.amp.autocast(enabled=True):\n","  while (cap.isOpened()):\n","    # load frame-by-frame\n","    _, frame = cap.read()\n","\n","    if frame is None or current_frame_index > frames_to_propagate:\n","      break\n","\n","    if current_frame_index % 100 == 0:\n","      print('Frame No.: ', current_frame_index)\n","\n","    # convert numpy array to pytorch tensor format\n","    frame_torch, _ = image_to_torch(frame, device=device)\n","    if current_frame_index == 0:\n","      # initialize with the mask\n","      mask_torch = index_numpy_to_one_hot_torch(mask, num_objects+1).to(device)\n","      # remove background when feeding into the model\n","      prediction = processor.step(frame_torch, mask_torch[1:])\n","\n","    else:\n","      # propagate only\n","      prediction = processor.step(frame_torch)\n","\n","    # argmax, convert to numpy\n","    player1_mask = torch.stack([prediction[0], prediction[1], prediction[1]])\n","    player2_mask = torch.stack([prediction[0], prediction[2], prediction[2]])\n","    person_mask = torch.stack([prediction[0], prediction[3], prediction[3]])\n","\n","    player1_mask = torch_prob_to_numpy_mask(player1_mask) #白選手\n","    player2_mask = torch_prob_to_numpy_mask(player2_mask) #青選手\n","    person_mask = torch_prob_to_numpy_mask(person_mask) #審判\n","    # cv2_imshow(player1_mask*255)\n","    # cv2_imshow(player2_mask*255)\n","    # cv2_imshow(person_mask*255)\n","\n","\n","    prediction = torch_prob_to_numpy_mask(prediction)\n","    # cv2_imshow(prediction*255)\n","    if current_frame_index % visualize_every == 0:\n","      visualization = overlay_davis(frame, prediction)\n","      #display(Image.fromarray(visualization))\n","\n","      # セグメント保存\n","      segment_writer.write(visualization)\n","      # マスク保存\n","\n","      player1_mask = cv2.cvtColor(player1_mask*255, cv2.COLOR_GRAY2BGR)\n","      player2_mask = cv2.cvtColor(player2_mask*255, cv2.COLOR_GRAY2BGR)\n","      person_mask = cv2.cvtColor(person_mask*255, cv2.COLOR_GRAY2BGR)\n","\n","      #mask_single = cv2.cvtColor(prediction * 255, cv2.COLOR_GRAY2BGR)\n","      person1_mask_writer.write(player1_mask)\n","      person2_mask_writer.write(player2_mask)\n","      person3_mask_writer.write(person_mask)\n","      first_frame += 1\n","\n","    current_frame_index += 1\n","\n","segment_writer.release()\n","person1_mask_writer.release()\n","person2_mask_writer.release()\n","person3_mask_writer.release()\n","cap.release()\n","# cv2.destroyAllWindows()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"24bXeY-XdSR_"},"source":["## 動画の切り抜き（オクルージョン対策）"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fGU5MFgGxAGd"},"source":["# E2FGVI"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Dl0geaqIDr-5"},"source":["## 環境セットアップ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1672816905503,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"ILWwzOnndgab","outputId":"c89eaa69-aa07-465b-9c50-cb13a9cc3036"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["# /content に戻る\n","%cd /content"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"I0fVT2GdDr-6"},"source":["## GPU確認"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GS-bLs5jagc"},"outputs":[],"source":["# import torch\n","# torch.cuda.empty_cache()\n","\n","# import gc\n","# gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1117,"status":"ok","timestamp":1672816906603,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"2PcII5fLdHnJ","outputId":"66ef4003-21d3-43d3-c849-d4dc43b034a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Jan  4 07:21:45 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Zshu3r5PDr-7"},"source":["## GitHubからコード取得"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Rii6XmjZDr-9"},"source":["## ライブラリのインストール"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3251,"status":"ok","timestamp":1672816909849,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"1b6kOBPsnfGq","outputId":"5677fca7-eeea-4b7d-ad35-ee8e5927710c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Cloning into 'E2FGVI'...\n","remote: Enumerating objects: 342, done.\u001b[K\n","remote: Counting objects: 100% (73/73), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 342 (delta 47), reused 35 (delta 35), pack-reused 269\u001b[K\n","Receiving objects: 100% (342/342), 36.75 MiB | 20.54 MiB/s, done.\n","Resolving deltas: 100% (52/52), done.\n"]}],"source":["# # prepare code\n","import os\n","CODE_DIR = 'E2FGVI'\n","os.makedirs(f'./{CODE_DIR}')\n","# !git clone https://github.com/MCG-NKU/E2FGVI.git $CODE_DIR\n","# os.chdir(f'./{CODE_DIR}')\n","\n","%cd /content\n","\n","!git clone https://github.com/MCG-NKU/E2FGVI.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90110,"status":"ok","timestamp":1672816999955,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"LScsvO3UppqT","outputId":"756ba953-63f2-4562-bfa8-1a084194135c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.5.1+cu101\n","  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp38-cp38-linux_x86_64.whl (704.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.4/704.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.6.1+cu101\n","  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp38-cp38-linux_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.5.1+cu101) (1.21.6)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.6.1+cu101) (7.1.2)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.0+cu116\n","    Uninstalling torch-1.13.0+cu116:\n","      Successfully uninstalled torch-1.13.0+cu116\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.14.0+cu116\n","    Uninstalling torchvision-0.14.0+cu116:\n","      Successfully uninstalled torchvision-0.14.0+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.5.1+cu101 which is incompatible.\n","torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.5.1+cu101 which is incompatible.\n","fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.5.1+cu101 which is incompatible.\n","fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.6.1+cu101 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n","Collecting mmcv-full\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/mmcv_full-1.7.1-cp38-cp38-manylinux1_x86_64.whl (45.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (1.21.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (6.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (7.1.2)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (21.3)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (4.6.0.66)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->mmcv-full) (3.0.9)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.7.1 yapf-0.32.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n","Collecting gdown\n","  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.4.0\n","    Uninstalling gdown-4.4.0:\n","      Successfully uninstalled gdown-4.4.0\n","Successfully installed gdown-4.6.0\n"]}],"source":["#@title Setup environment and code (may take some time)\n","\n","# Install Pytorch\n","!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","# Install MMCV\n","!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n","# Install gdown\n","!pip install --upgrade gdown"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8olrgLpYEzWq"},"source":["## 学習済みモデルのダウンロード"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409,"status":"ok","timestamp":1672819286295,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"KP2adMBRzDOg","outputId":"e5a773b3-df41-4325-8b67-6cc1debe21d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/E2FGVI\n"]}],"source":["%cd /content/E2FGVI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17012,"status":"ok","timestamp":1672819319425,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"xwyzDJ1wE1G6","outputId":"de878be7-b776-4e72-9761-76f4815d5d42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  E2FGVI_CVPR22_models.zip\n","  inflating: E2FGVI-CVPR22.pth       \n","  inflating: i3d_rgb_imagenet.pt     \n"]}],"source":["#@title Download model with PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import os\n","\n","download_with_pydrive = True\n","CODE_DIR = \"E2FGVI\"\n","class Downloader(object):\n","    def __init__(self, use_pydrive):\n","        self.use_pydrive = use_pydrive\n","        current_directory = os.getcwd()\n","        self.save_dir = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"release_model\")\n","        if not os.path.exists(self.save_dir):\n","            os.makedirs(self.save_dir)\n","        if self.use_pydrive:\n","            self.authenticate()\n","\n","    def authenticate(self):\n","        auth.authenticate_user()\n","        gauth = GoogleAuth()\n","        gauth.credentials = GoogleCredentials.get_application_default()\n","        self.drive = GoogleDrive(gauth)\n","\n","    def download_file(self, file_id, file_name):\n","        file_dst = f'{self.save_dir}/{file_name}'\n","        if os.path.exists(file_dst):\n","            print(f'{file_name} already exists!')\n","            return\n","        downloaded = self.drive.CreateFile({'id':file_id})\n","        downloaded.FetchMetadata(fetch_all=True)\n","        downloaded.GetContentFile(file_dst)\n","\n","downloader = Downloader(download_with_pydrive)\n","# 画像サイズ固定モデル　古い\n","path = {\"id\": \"1tNJMTJ2gmWdIXJoHVi5-H504uImUiJW9\", \"name\": \"E2FGVI_CVPR22_models.zip\"}\n","downloader.download_file(file_id=path[\"id\"], file_name=path[\"name\"])\n","os.chdir(downloader.save_dir)\n","# 画像サイズ任意モデル　新しい\n","path = {\"id\": \"10wGdKSUOie0XmCr8SQ2A2FeDe-mfn5w3\", \"name\": \"E2FGVI-HQ-CVPR22.pth\"}\n","downloader.download_file(file_id=path[\"id\"], file_name=path[\"name\"])\n","os.chdir(downloader.save_dir)\n","\n","!unzip E2FGVI_CVPR22_models.zip\n","os.chdir('..')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gI0sSprNw6Yv"},"source":["## 関数定義"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1672817162065,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"i5_OQ6UhpciJ","outputId":"e4e22cd0-6f1e-48b8-d99d-78cb918d74e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/E2FGVI\n"]}],"source":["%cd /content/E2FGVI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXzOYSSBw3lI"},"outputs":[],"source":["# def read_mask(mpath):\n","#     mname = mpath\n","#     masks = []\n","#     mnames = os.listdir(mname)\n","#     mnames.sort()\n","#     fr_lst = [mname+'/'+name_ for name_ in mnames]\n","#     for mp in mnames:\n","#         m = Image.fromarray(cv2.imread(mp))\n","#         m = m.resize((w, h), Image.NEAREST)\n","#         m = np.array(m.convert('L'))\n","#         m = np.array(m > 0).astype(np.uint8)\n","#         m = cv2.dilate(m, cv2.getStructuringElement(\n","#             cv2.MORPH_CROSS, (3, 3)), iterations=4)\n","#         masks.append(Image.fromarray(m*255))\n","#     return masks\n","\n","\n","#  read frames from video\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import animation\n","\n","import cv2\n","from PIL import Image\n","import numpy as np\n","import importlib\n","import os\n","import argparse\n","from tqdm import tqdm\n","import torch\n","\n","# rc('animation', html='jshtml')\n","\n","from core.utils import to_tensors\n","\n","\n","# global variables\n","w, h = 640, 360\n","ref_length = 10  # ref_step\n","num_ref = -1\n","neighbor_stride = 5\n","\n","\n","# sample reference frames from the whole video\n","def get_ref_index(f, neighbor_ids, length):\n","    ref_index = []\n","    if num_ref == -1:\n","        for i in range(0, length, ref_length):\n","            if i not in neighbor_ids:\n","                ref_index.append(i)\n","    else:\n","        start_idx = max(0, f - ref_length * (num_ref//2))\n","        end_idx = min(length, f + ref_length * (num_ref//2))\n","        for i in range(start_idx, end_idx+1, ref_length):\n","            if i not in neighbor_ids:\n","                if len(ref_index) > num_ref:\n","                    break\n","                ref_index.append(i)\n","    return ref_index\n","\n","\n","# read frame-wise masks\n","def read_mask(mpath):\n","    masks = []\n","    mnames = os.listdir(mpath)\n","    mnames.sort()\n","    for mp in mnames:\n","        m = Image.open(os.path.join(mpath, mp))\n","        m = m.resize((w, h), Image.NEAREST)\n","        m = np.array(m.convert('L'))\n","        m = np.array(m > 0).astype(np.uint8)\n","        m = cv2.dilate(m, cv2.getStructuringElement(\n","            cv2.MORPH_CROSS, (3, 3)), iterations=4)\n","        masks.append(Image.fromarray(m*255))\n","    return masks\n","\n","\n","#  read frames from video\n","def read_frame_from_videos(video_path):\n","    vname = video_path\n","    frames = []\n","    lst = os.listdir(vname)\n","    lst.sort()\n","    fr_lst = [vname+'/'+name for name in lst]\n","    for fr in fr_lst:\n","        image = cv2.imread(fr)\n","        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","        frames.append(image.resize((w, h)))\n","    return frames"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nYS7U8QexNZC"},"source":["## Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrq7pVxBxRc7"},"outputs":[],"source":["# set up models\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","# net = importlib.import_module('model.e2fgvi')\n","net = importlib.import_module('model.e2fgvi_hq')\n","model = net.InpaintGenerator().to(device)\n","# ckpt_path = 'release_model/E2FGVI-CVPR22.pth'\n","ckpt_path = 'release_model/E2FGVI-HQ-CVPR22.pth'\n","data = torch.load(ckpt_path, map_location=device)\n","model.load_state_dict(data)\n","print(f'Loading model from: {ckpt_path}')\n","model.eval()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yPPJ8Uz_xWan"},"source":["## 動画編集のため"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Zh5vs5-FqjHd"},"source":["トリミングしたいなら、クリック ここ\n","<!-- 元動画をトリミングする\n","\n","参考：\n","\n","https://w.atwiki.jp/kobapan/pages/173.html\n","\n","ffmpeg　-i　変換前ファイル　-vf crop= 出力動画の幅 : 出力動画の高さ : 元動画の左上をゼロとして X 軸の距離 : 元動画の左上をゼロとして Y 軸の距離 -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oPXmFSitp6hB"},"outputs":[],"source":["!rm -fr /content/E2FGVI/examples/schoolgirls_mask\n","!rm -fr /content/E2FGVI/examples/tennis\n","!rm -fr /content/E2FGVI/examples/tennis_mask\n","!rm -fr /content/E2FGVI/examples/schoolgirls.mp4"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mQQzQDZavWX6"},"source":["元動画をカット　0から数えて900フレームから"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275313,"status":"ok","timestamp":1672817464811,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"9TmsKsc5qYBS","outputId":"e787a109-156b-4ba8-ce6c-35e064286bac"},"outputs":[{"name":"stdout","output_type":"stream","text":["ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/Colab Notebooks/2018WCB_60_P2_SELLO Edwin_BOT_NAZIR BIN Abdou_MAD.mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: isommp42\n","    creation_time   : 2018-09-20T12:28:31.000000Z\n","  Duration: 00:03:16.37, start: 0.000000, bitrate: 2154 kb/s\n","    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 2025 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n","    Metadata:\n","      creation_time   : 2018-09-20T12:28:31.000000Z\n","      handler_name    : ISO Media file produced by Google Inc. Created on: 09/20/2018.\n","    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 125 kb/s (default)\n","    Metadata:\n","      creation_time   : 2018-09-20T12:28:31.000000Z\n","      handler_name    : ISO Media file produced by Google Inc. Created on: 09/20/2018.\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0musing SAR=1/1\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mprofile High, level 3.1\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to '/content/str901frame_mv.mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: isommp42\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], q=-1--1, 25 fps, 12800 tbn, 25 tbc (default)\n","    Metadata:\n","      creation_time   : 2018-09-20T12:28:31.000000Z\n","      handler_name    : ISO Media file produced by Google Inc. Created on: 09/20/2018.\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame= 4009 fps= 15 q=-1.0 Lsize=   47128kB time=00:02:40.24 bitrate=2409.3kbits/s speed=0.586x    \n","video:47080kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.101284%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mframe I:17    Avg QP:20.66  size: 87939\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mframe P:1069  Avg QP:23.20  size: 25907\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mframe B:2923  Avg QP:27.05  size:  6507\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mconsecutive B-frames:  0.8%  3.2%  8.2% 87.8%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mmb I  I16..4: 16.1% 47.6% 36.3%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mmb P  I16..4:  6.7%  9.1%  4.6%  P16..4: 38.1% 18.6% 10.3%  0.0%  0.0%    skip:12.7%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mmb B  I16..4:  1.1%  1.2%  0.7%  B16..8: 43.6%  6.5%  1.0%  direct: 1.7%  skip:44.2%  L0:44.0% L1:50.1% BI: 5.9%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0m8x8 transform intra:43.6% inter:60.8%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mcoded y,uvDC,uvAC intra: 44.9% 81.1% 42.3% inter: 11.5% 19.5% 1.7%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mi16 v,h,dc,p: 18% 56% 12% 14%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 27% 26%  4%  5%  5%  6%  5%  6%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 24% 16%  5%  7%  8%  7%  6%  5%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mi8c dc,h,v,p: 36% 39% 15% 10%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mref P L0: 69.7% 12.3% 13.1%  4.9%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mref B L0: 90.0%  8.1%  1.8%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mref B L1: 96.9%  3.1%\n","\u001b[1;36m[libx264 @ 0x56160febed00] \u001b[0mkb/s:2405.05\n"]}],"source":["!ffmpeg -i '/content/drive/MyDrive/Colab Notebooks/2018WCB_60_P2_SELLO Edwin_BOT_NAZIR BIN Abdou_MAD.mp4' -vf trim=start_frame=900:end_frame=4909,setpts=PTS-STARTPTS -an '/content/str901frame_mv.mp4'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8Glrpw-nbALT"},"source":["## 元動画"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ubHQl1Qr3eyy"},"source":["ffmpegで１０秒ごとの動画を作成\n","\n","参考：\n","https://qiita.com/hosota9/items/29f845854db2e4eeebc0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNAmKTAVsfmd"},"outputs":[],"source":["# !for f in /content/output_*.mp4; do rm -fr ${f}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPRQFqfUxVv5"},"outputs":[],"source":["# # 元動画から１０秒ごとの動画を作成\n","# !ffmpeg -i '/content/str901frame_mv.mp4' -map 00 -c copy -f segment -segment_time 10 -reset_timestamps 1 '/content/output_%01d.mp4'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwWGa_HDuEnh"},"outputs":[],"source":["# !for f in /content/E2FGVI/examples/zyudou*; do rm -fr ${f}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8zivATJ4noZ"},"outputs":[],"source":["# 分割した動画の数だけ画像を入れるフォルダを作成\n","!for f in /content/output_*.mp4; do mkdir -p /content/E2FGVI/examples/zyudou{0..16}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTkL4i3fJEA3"},"outputs":[],"source":["# # 作成したフォルダそれぞれに画像を保存\n","# !for f in {0..16}; do ffmpeg -i /content/output_${f}.mp4 /content/E2FGVI/examples/zyudou${f}/%05d.png; done"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324715,"status":"ok","timestamp":1672819049654,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"th_sU33zw4vc","outputId":"409512bb-3f0c-413a-a676-1a84ba5c5bc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/str901frame_mv.mp4':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2avc1mp41\n","    encoder         : Lavf57.83.100\n","  Duration: 00:02:40.36, start: 0.000000, bitrate: 2407 kb/s\n","    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2405 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n","Press [q] to stop, [?] for help\n","Output #0, image2, to '/content/E2FGVI/examples/zyudou_img/%05d.png':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2avc1mp41\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: png, rgb24, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","      encoder         : Lavc57.107.100 png\n","frame= 4009 fps= 12 q=-0.0 Lsize=N/A time=00:02:40.36 bitrate=N/A speed=0.495x    \n","video:5019917kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"]}],"source":["!mkdir /content/E2FGVI/examples/zyudou_img\n","!ffmpeg -i '/content/str901frame_mv.mp4' '/content/E2FGVI/examples/zyudou_img/%05d.png'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":489,"status":"ok","timestamp":1672819126238,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"49IeRuRhxH8a","outputId":"3c24d821-0e51-4d82-c498-9528d68f38be"},"outputs":[{"name":"stdout","output_type":"stream","text":["4009\n"]}],"source":["import glob\n","a = glob.glob('/content/E2FGVI/examples/zyudou_img/*.png')\n","print(len(a))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8OFm86uvxKqm"},"outputs":[],"source":["# 分割した動画の数だけ画像を入れるフォルダを作成\n","# オリジナル動画\n","!for f in {0..41}; do mkdir -p /content/E2FGVI/examples/zyudou_img{0..41}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dI5xbl9m8PtY"},"outputs":[],"source":["from os import listdir\n","import shutil\n","\n","#マスク動画の4009枚を100枚づつ各フォルダ(計41)　に振り分ける\n","a = 0\n","folder_num = 41\n","img_num = 100\n","for i in range(folder_num):\n","  if i !=folder_num - 1:\n","    for j in range(img_num):\n","        shutil.move(f\"/content/E2FGVI/examples/zyudou_img/{str(j+a+1).zfill(5)}.png\", f\"/content/E2FGVI/examples/zyudou_img{i}\")\n","  else:\n","    for k in range(len(glob.glob('/content/E2FGVI/examples/whitezyudou_mask/*.png'))):\n","      shutil.move(f\"/content/E2FGVI/examples/zyudou_img/{str(k+a+1).zfill(5)}.png\", f\"/content/E2FGVI/examples/zyudou_img{i}\")\n","  a +=img_num"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A7x2SfIObGmg"},"source":["## マスク動画"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2UeDiO__Rou"},"outputs":[],"source":["# !for f in /content/whitemask_output_*.mp4; do rm -fr ${f}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6qx2qbOz0Ox"},"outputs":[],"source":["# !rm -fr /content/E2FGVI/examples/whitezyudou_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85356,"status":"ok","timestamp":1672819608356,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"LonHazVsEOlh","outputId":"3763e655-a2aa-4a82-f90f-f601487e917d"},"outputs":[{"name":"stdout","output_type":"stream","text":["ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/Colab Notebooks/sports_compe/white_mask.mp4':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2mp41\n","    encoder         : Lavf58.76.100\n","  Duration: 00:02:40.36, start: 0.000000, bitrate: 2903 kb/s\n","    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2902 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (mpeg4 (native) -> png (native))\n","Press [q] to stop, [?] for help\n","Output #0, image2, to '/content/E2FGVI/examples/whitezyudou_mask/%05d.png':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2mp41\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: png, rgb24, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","      encoder         : Lavc57.107.100 png\n","frame= 4009 fps= 49 q=-0.0 Lsize=N/A time=00:02:40.36 bitrate=N/A speed=1.95x    \n","video:99899kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"]}],"source":["# 動画を画像にする\n","!mkdir /content/E2FGVI/examples/whitezyudou_mask\n","!ffmpeg -i '/content/drive/MyDrive/Colab Notebooks/sports_compe/white_mask.mp4' '/content/E2FGVI/examples/whitezyudou_mask/%05d.png'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1672819608356,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"EbTdlm6szXXR","outputId":"04c570d6-053b-4a36-fe4b-b8be4d3fc3ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["4009\n"]}],"source":["import glob\n","a = glob.glob('/content/E2FGVI/examples/whitezyudou_mask/*.png')\n","print(len(a))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZpAA97zcMtj"},"outputs":[],"source":["# # 元動画から１０秒ごとの動画を作成\n","# # 白選手用\n","# !ffmpeg -i '/content/drive/MyDrive/Colab Notebooks/for_sports/white_mask.mp4' -map 0 -c copy -f segment -segment_time 10 -reset_timestamps 1 '/content/whitemask_output_%01d.mp4'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Ymyqp-ybQfl"},"outputs":[],"source":["# 分割した動画の数だけ画像を入れるフォルダを作成\n","# オリジナル動画\n","!for f in {0..40}; do mkdir -p /content/E2FGVI/examples/whitezyudou_mask{0..40}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cuM9hZwfF7jc"},"outputs":[],"source":["from os import listdir\n","import shutil\n","\n","#マスク動画の4009枚を100枚づつ各フォルダ(計41)　に振り分ける\n","a = 0\n","folder_num = 41\n","img_num = 100\n","for i in range(folder_num):\n","  if i !=folder_num - 1:\n","    for j in range(img_num):\n","        shutil.move(f\"/content/E2FGVI/examples/whitezyudou_mask/{str(j+a+1).zfill(5)}.png\", f\"/content/E2FGVI/examples/whitezyudou_mask{i}\")\n","  else:\n","    for k in range(len(glob.glob('/content/E2FGVI/examples/whitezyudou_mask/*.png'))):\n","      shutil.move(f\"/content/E2FGVI/examples/whitezyudou_mask/{str(k+a+1).zfill(5)}.png\", f\"/content/E2FGVI/examples/whitezyudou_mask{i}\")\n","  a +=img_num"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6_kRGv5zlLb"},"outputs":[],"source":["# # 作成したフォルダそれぞれに画像を保存\n","# # 白選手用\n","# !for f in {0..16}; do ffmpeg -i /content/whitemask_output_${f}.mp4 /content/E2FGVI/examples/whitezyudou_mask${f}/%05d.png; done"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qgoWnqwlGCZe"},"source":["審判"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70471,"status":"ok","timestamp":1672819889569,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"iMBY1yL9Kct5","outputId":"39fc7589-c391-459e-9663-decf5efe7529"},"outputs":[{"name":"stdout","output_type":"stream","text":["ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/Colab Notebooks/sports_compe/referee_mask.mp4':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2mp41\n","    encoder         : Lavf58.76.100\n","  Duration: 00:02:40.36, start: 0.000000, bitrate: 1495 kb/s\n","    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 1494 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (mpeg4 (native) -> png (native))\n","Press [q] to stop, [?] for help\n","Output #0, image2, to '/content/E2FGVI/examples/personzyudou_mask/%05d.png':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2mp41\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: png, rgb24, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","      encoder         : Lavc57.107.100 png\n","frame= 4009 fps= 59 q=-0.0 Lsize=N/A time=00:02:40.36 bitrate=N/A speed=2.36x    \n","video:55565kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"]}],"source":["# 動画を画像にする\n","!mkdir /content/E2FGVI/examples/personzyudou_mask\n","!ffmpeg -i '/content/drive/MyDrive/Colab Notebooks/sports_compe/referee_mask.mp4' '/content/E2FGVI/examples/personzyudou_mask/%05d.png'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1672819889569,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"enmaGzDMze7Y","outputId":"8facdcce-e706-466b-f8b3-7b510ec49fa9"},"outputs":[{"name":"stdout","output_type":"stream","text":["4009\n"]}],"source":["import glob\n","a = glob.glob('/content/E2FGVI/examples/personzyudou_mask/*.png')\n","print(len(a))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DkvY_DChyRBd"},"outputs":[],"source":["# # 元動画から１０秒ごとの動画を作成\n","# # 審判用\n","# !ffmpeg -i '/content/drive/MyDrive/Colab Notebooks/for_sports/person_mask.mp4' -map 0:00:00 -c copy -f segment -segment_time 10:00:00 -reset_timestamps 1 '/content/person_mask_output_%01d.mp4'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isWwVltCy4_A"},"outputs":[],"source":["# 分割した動画の数だけ画像を入れるフォルダを作成\n","# 審判用\n","!for f in {0..40}; do mkdir -p /content/E2FGVI/examples/personzyudou_mask{0..40}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTwvKrmFbZ9l"},"outputs":[],"source":["# # 作成したフォルダそれぞれに画像を保存\n","# # 審判用\n","# !for f in {0..16}; do ffmpeg -i /content/person_mask_output_${f}.mp4 /content/E2FGVI/examples/personzyudou_mask${f}/%05d.png; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xRVyk8nLEy-"},"outputs":[],"source":["from os import listdir\n","import shutil\n","\n","#マスク動画の4009枚を100枚づつ各フォルダ(計41)　に振り分ける\n","a = 0\n","folder_num = 41\n","img_num = 100\n","for i in range(folder_num):\n","  if i !=folder_num - 1:\n","    for j in range(img_num):\n","        shutil.move(f\"/content/E2FGVI/examples/personzyudou_mask/{str(j+a+1).zfill(5)}.png\", f\"/content/E2FGVI/examples/personzyudou_mask{i}\")\n","  else:\n","    for k in range(len(glob.glob('/content/E2FGVI/examples/personzyudou_mask/*.png'))):\n","      shutil.move(f\"/content/E2FGVI/examples/personzyudou_mask/{str(k+a+1).zfill(5)}.png\", f\"/content/E2FGVI/examples/personzyudou_mask{i}\")\n","  a +=img_num"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1672819995860,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"9AxGJjBZN0vW","outputId":"934f58bb-b5eb-4759-ed38-8dbdf50164b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["9\n"]}],"source":["import glob\n","v = glob.glob('/content/E2FGVI/examples/personzyudou_mask40/*.png')\n","print(len(v))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xbJnEpJs0DYb"},"source":["白選手と審判のマスク画像をcv2.bitwise_andで合成する"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":393,"status":"ok","timestamp":1672820018500,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"5drN8VrHKLkA","outputId":"f6b64de0-4591-48e9-cbdb-41332e469a00"},"outputs":[{"data":{"text/plain":["(40, 100)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["coordinates = np.zeros((40, 100))\n","coordinates.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kIZ7BvkTYwm0"},"outputs":[],"source":["# マスクフォルダを作成\n","# 全体のマスク用\n","!for f in {0..40}; do mkdir -p /content/E2FGVI/examples/zyudou_mask{0..40}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wj2DCI7Bt1Wl"},"outputs":[],"source":["import numpy as np\n","import cv2\n","\n","a = 0\n","folder_num = 41\n","img_num = 100\n","\n","# coordinates = np.zeros((16, 250))\n","# テストディレクトリにある「sam XXXX .csv」を取得する場合\n","for nb in range(folder_num):\n","  name1 = glob.glob(f\"/content/E2FGVI/examples/personzyudou_mask{nb}/*.png\")\n","  name2 = glob.glob(f\"/content/E2FGVI/examples/whitezyudou_mask{nb}/*.png\")\n","  name1 = sorted(name1)\n","  name2 = sorted(name2)\n","  # print(name1)\n","  # print(name2)\n","  # print(nb)\n","  # print(len(name1))\n","  # print(len(name2))\n","\n","  for i in range(0, len(name1)):\n","    if nb != folder_num - 1:\n","      filename1 = name1[i]\n","      filename2 = name2[i]\n","      temp1 = cv2.imread(filename1)\n","      temp2 = cv2.imread(filename2)\n","      temp = cv2.bitwise_or(temp1, temp2)\n","      cv2.imwrite(f'/content/E2FGVI/examples/zyudou_mask{nb}/{name2[i][44:53]}', temp)\n","    else:\n","      for k in range(len(glob.glob(f'/content/E2FGVI/examples/personzyudou_mask{nb}/*.png'))):\n","        filename1 = name1[k]\n","        filename2 = name2[k]\n","        temp1 = cv2.imread(filename1)\n","        temp2 = cv2.imread(filename2)\n","        temp = cv2.bitwise_or(temp1, temp2)\n","        cv2.imwrite(f'/content/E2FGVI/examples/zyudou_mask{nb}/{name2[k][44:53]}', temp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jiw6_zqpT_w1"},"outputs":[],"source":["#　結果を保存するフォルダを作成\n","# %cd /content/E2FGVI\n","!for f in {0..40}; do mkdir -p /content/E2FGVI/results${f}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXmdcDwp46Uw"},"outputs":[],"source":["# CUDA_LAUNCH_BLOCKING=1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"elapsed":534,"status":"error","timestamp":1672820328467,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"a_kK40JsS8SO","outputId":"604abc15-02d9-4f48-e42f-90c2fb3ddba3"},"outputs":[],"source":["# prepare dataset\n","\n","a = 0\n","folder_num = 41\n","img_num = 100\n","\n","for nb in range(folder_num):\n","  video_path = f'/content/E2FGVI/examples/zyudou_img{nb}'\n","  mask_path = f'/content/E2FGVI/examples/zyudou_mask{nb}'\n","  print(f'Loading videos and masks from: {video_path}')\n","  frames = read_frame_from_videos(video_path)\n","  video_length = len(frames)\n","  imgs = to_tensors()(frames).unsqueeze(0) * 2 - 1\n","  frames = [np.array(f).astype(np.uint8) for f in frames]\n","\n","  masks = read_mask(mask_path)\n","  binary_masks = [np.expand_dims((np.array(m) != 0).astype(np.uint8), 2)\n","                  for m in masks]\n","  masks = to_tensors()(masks).unsqueeze(0)\n","  imgs, masks = imgs.to(device), masks.to(device)\n","  comp_frames = [None] * video_length\n","\n","  import torch\n","  torch.cuda.empty_cache()\n","\n","  import gc\n","  gc.collect()\n","\n","  # completing holes by e2fgvi\n","  print(f'Start test...')\n","  for f in tqdm(range(0, video_length, neighbor_stride)):\n","      neighbor_ids = [i for i in range(max(0, f-neighbor_stride), min(video_length, f+neighbor_stride+1))]\n","      ref_ids = get_ref_index(f, neighbor_ids, video_length)\n","      selected_imgs = imgs[:1, neighbor_ids+ref_ids, :, :, :]\n","      selected_masks = masks[:1, neighbor_ids+ref_ids, :, :, :]\n","      with torch.no_grad():\n","          masked_imgs = selected_imgs*(1-selected_masks)\n","          pred_img, _ = model(masked_imgs, len(neighbor_ids))\n","\n","          pred_img = (pred_img + 1) / 2\n","          pred_img = pred_img.cpu().permute(0, 2, 3, 1).numpy() * 255\n","          for i in range(len(neighbor_ids)):\n","              idx = neighbor_ids[i]\n","              img = np.array(pred_img[i]).astype(\n","                  np.uint8)*binary_masks[idx] + frames[idx] * (1-binary_masks[idx])\n","              if comp_frames[idx] is None:\n","                  comp_frames[idx] = img\n","              else:\n","                  comp_frames[idx] = comp_frames[idx].astype(\n","                      np.float32)*0.5 + img.astype(np.float32)*0.5\n","\n","  import matplotlib.pyplot as plt\n","\n","  # 推論結果出力\n","  for i, frame in enumerate(comp_frames):\n","    print(f'results{nb}')\n","    plt.imsave(f'results{nb}/frames_%06d.png'%(i), frame.astype(np.uint8))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EqoR7lj2es4B"},"source":["## 画像を動画に変換して表示"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GuE8l9oew1r"},"outputs":[],"source":["# colabのpythonが3.7　原因なのか　バージョンを下げる必要がある\n","!pip install moviepy==1.0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hc8y3f3eZ4a"},"outputs":[],"source":["!mkdir -p /content/result_mv\n","\n","# from moviepy.editor import *\n","# from moviepy.video.fx.resize import resize\n","\n","frames_path = '/content/E2FGVI/results${f}/frames_%06d.png'\n","result_video = '/content/result_mv/result${f}.mp4'\n","!ffmpeg -i {frames_path} -c:v libx264 -vf \"fps=25,format=yuv420p\" {result_video}\n","\n","#!for f in {0..16}; do ffmpeg -i {frames_path} -c:v libx264 -vf \"fps=25,format=yuv420p\" {result_video}; done\n","\n","# clip = VideoFileClip(result_video)\n","# # resize_clip = resize(clip, height=400)\n","# # resize_clip.ipython_display()\n","# clip.ipython_display()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":982,"status":"ok","timestamp":1669798278684,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"mCATlFFdhvcw","outputId":"da113506-5288-4e0a-aa60-7305b57fdc8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/result_mv/result16.mp4\n"]}],"source":["# !for f in {0..16}; do echo \"/content/result_mv/result${f}.mp4\" > /content/resultlist.txt ; done\n","# !cat /content/resultlist.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEHn6osFN28c"},"outputs":[],"source":["for i in range(40):\n","    f = open('/content/resultlist.txt', 'a')\n","    f.write(f\"file '/content/E2FGVI/results/zyudou_img{i}_results.mp4'\\n\")\n","    f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1511,"status":"ok","timestamp":1672826467007,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"U3Ls5MewiA-o","outputId":"e42f5461-59e5-4a65-ee2d-0e1cdeb2c616"},"outputs":[{"name":"stdout","output_type":"stream","text":["ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, concat, from '/content/resultlist.txt':\n","  Duration: N/A, start: 0.000000, bitrate: 3963 kb/s\n","    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 640x360 [SAR 1:1 DAR 16:9], 3963 kb/s, 24 fps, 24 tbr, 12288 tbn, 12288 tbc\n","    Metadata:\n","      handler_name    : VideoHandler\n","Output #0, mp4, to '/content/e2fgv_zyudou.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 640x360 [SAR 1:1 DAR 16:9], q=2-31, 3963 kb/s, 24 fps, 24 tbr, 12288 tbn, 12288 tbc\n","    Metadata:\n","      handler_name    : VideoHandler\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (copy)\n","Press [q] to stop, [?] for help\n","frame= 4000 fps=0.0 q=-1.0 Lsize=   69709kB time=00:02:46.63 bitrate=3426.9kbits/s speed= 909x    \n","video:69690kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.027990%\n"]}],"source":["!ffmpeg -f concat -safe 0 -i /content/resultlist.txt -c copy /content/e2fgv_zyudou.mp4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6Wh1GA6sM6V"},"outputs":[],"source":["%%bash\n","for i in {0..40}\n","do\n","python test.py --model e2fgvi_hq --video /content/E2FGVI/examples/zyudou_img${i} --mask /content/E2FGVI/examples/zyudou_mask${i}  --ckpt release_model/E2FGVI-HQ-CVPR22.pth --set_size --width 640 --height 360\n","done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"exh8ZBmPLneS"},"outputs":[],"source":["%%bash\n","for i in {0..40}\n","do\n","echo file /content/E2FGVI/results/zyudou_img${f}_results.mp4 > /content/resultlist.txt\n","done\n","#!for f in {0..16}; do ffmpeg -i {frames_path} -c:v libx264 -vf \"fps=25,format=yuv420p\" {result_video}; done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAwtnW3s7ktD"},"outputs":[],"source":["!python test.py --model e2fgvi_hq --video /content/E2FGVI/examples/zyudou_img40 --mask /content/E2FGVI/examples/zyudou_mask40  --ckpt release_model/E2FGVI-HQ-CVPR22.pth --set_size --width 640 --height 360"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVHaeCfqxbZY"},"outputs":[],"source":["# colabのpythonが3.7　原因なのか　バージョンを下げる必要がある\n","!pip install moviepy==1.0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbzQ10XJyInH"},"outputs":[],"source":["from moviepy.editor import *\n","from moviepy.video.fx.resize import resize\n","\n","frames_path = \"results/frames_%06d.png\"\n","result_video = \"/content/result0-249.mp4\"\n","\n","!ffmpeg -i {frames_path} -c:v libx264 -vf \"fps=25,format=yuv420p\" {result_video}\n","\n","clip = VideoFileClip(result_video)\n","# resize_clip = resize(clip, height=400)\n","# resize_clip.ipython_display()\n","clip.ipython_display()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y1dPb6uU8Rvr"},"source":["# bboxで選手を切り抜く\n","\n","青選手のマスクを用いて、e2fgvi適応動画を切り抜いてみる"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1669799526330,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"hACvCV1m-m5L","outputId":"c210ac6c-34a4-42a9-9443-16b4129807f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdlWzXn_7atQ"},"outputs":[],"source":["import for_sports.make_bboxclipping_img as make_bboxclipping_img\n","import cv2\n","import numpy as np\n","\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26mMT66OloOP"},"outputs":[],"source":["!mkdir /content/bbox_clipping"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669801969764,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"xEDcHDJo8hyX","outputId":"c31052d0-6685-4318-ebb4-ca73e7b7de79"},"outputs":[],"source":["cv2_imshow(cv2.imread(\"/content/bbox_clipping/04008.png\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q41HHzIC-1lR"},"outputs":[],"source":["bluemask_cap = cv2.VideoCapture(\"/content/drive/MyDrive/Colab Notebooks/for_sports/blue_mask.mp4\")\n","whitemask_cap = cv2.VideoCapture(\"/content/drive/MyDrive/Colab Notebooks/for_sports/white_mask.mp4\")\n","e2fgvi_cap = cv2.VideoCapture(\"/content/e2fgv_zyudou.mp4\")\n","\n","ct = 0\n","while True:\n","  bluemask_ret, img_bluemask = bluemask_cap.read()\n","  whitemask_ret, img_whitemask = whitemask_cap.read()\n","  e2fgvi_ret, img_e2fgvi = e2fgvi_cap.read()\n","  if not (bluemask_ret and e2fgvi_ret):\n","    break\n","  img_mask = cv2.cvtColor(cv2.resize(img_bluemask, (int(img_e2fgvi.shape[1]), int(img_e2fgvi.shape[0])), interpolation=cv2.INTER_LINEAR), cv2.COLOR_BGR2GRAY)\n","\n","  # img_e2fgvi = cv2.cvtColor(img_e2fgvi, cv2.COLOR_BGR2GRAY)\n","\n","  img_bbox =  cv2.cvtColor(make_bboxclipping_img.bbox_for_mask1(img_mask, now_frame=900), cv2.COLOR_GRAY2RGB)\n","  player_mask = cv2.cvtColor(cv2.bitwise_or(cv2.cvtColor(cv2.resize(img_bluemask, (int(img_e2fgvi.shape[1]), int(img_e2fgvi.shape[0])), interpolation=cv2.INTER_LINEAR), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.resize(img_whitemask, (int(img_e2fgvi.shape[1]), int(img_e2fgvi.shape[0])), interpolation=cv2.INTER_LINEAR), cv2.COLOR_BGR2GRAY)), cv2.COLOR_GRAY2RGB)\n","\n","  mask = cv2.bitwise_and(img_bbox, player_mask)\n","  img = cv2.bitwise_and(img_e2fgvi, mask)\n","  cv2_imshow(img)\n","  # img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","  cv2.imwrite(f'/content/bbox_clipping/{str(ct).zfill(5)}.png', img)\n","  ct += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1669807644361,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"-Wix2SU36hcv","outputId":"5a5274a3-fcdb-4e61-8dc4-1b76bb0618b6"},"outputs":[{"data":{"text/plain":["4009"]},"execution_count":165,"metadata":{},"output_type":"execute_result"}],"source":["len(glob.glob('/content/bbox_clipping/*.png'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46379,"status":"ok","timestamp":1669807690729,"user":{"displayName":"takuya mori","userId":"17902813538528058494"},"user_tz":-540},"id":"8pZTBIm_B4c0","outputId":"9f80e24c-e9e8-4d2b-f429-c8b029f01ba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/bbox_clipping/video’: File exists\n","ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, image2, from '/content/bbox_clipping/%05d.png':\n","  Duration: 00:02:40.36, start: 0.000000, bitrate: N/A\n","    Stream #0:0: Video: png, rgb24(pc), 432x240, 25 fps, 25 tbr, 25 tbn, 25 tbc\n","File '/content/bbox_clipping/video/bbox_clipping.mp4' already exists. Overwrite ? [y/N] y\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mprofile High, level 2.1\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to '/content/bbox_clipping/video/bbox_clipping.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 432x240, q=-1--1, 25 fps, 12800 tbn, 25 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame= 4009 fps=226 q=-1.0 Lsize=    3512kB time=00:02:40.24 bitrate= 179.6kbits/s speed=9.03x    \n","video:3465kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.367186%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mframe I:22    Avg QP: 9.71  size:  2667\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mframe P:1054  Avg QP:23.18  size:  1382\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mframe B:2933  Avg QP:26.17  size:   693\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mconsecutive B-frames:  1.4%  1.7%  4.3% 92.6%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mmb I  I16..4: 80.0%  6.8% 13.2%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mmb P  I16..4:  0.7%  3.2%  3.2%  P16..4:  4.6%  4.8%  2.6%  0.0%  0.0%    skip:80.8%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mmb B  I16..4:  0.2%  0.3%  0.5%  B16..8:  9.6%  5.2%  1.8%  direct: 0.9%  skip:81.6%  L0:46.0% L1:43.0% BI:11.0%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0m8x8 transform intra:35.3% inter:23.8%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mcoded y,uvDC,uvAC intra: 37.3% 50.2% 44.6% inter: 4.6% 5.1% 1.4%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mi16 v,h,dc,p: 83%  9%  7%  1%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 13% 10% 59%  3%  3%  3%  3%  3%  4%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 18% 31%  4%  4%  6%  4%  5%  4%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mi8c dc,h,v,p: 58% 16% 19%  6%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mWeighted P-Frames: Y:5.8% UV:2.8%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mref P L0: 55.7% 11.6% 20.5% 11.7%  0.6%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mref B L0: 84.4% 12.6%  3.0%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mref B L1: 95.4%  4.6%\n","\u001b[1;36m[libx264 @ 0x561aa9931e00] \u001b[0mkb/s:176.96\n"]}],"source":["!mkdir /content/bbox_clipping/video\n","frames_path = '/content/bbox_clipping/%05d.png'\n","result_video = '/content/bbox_clipping/video/bbox_clipping.mp4'\n","\n","!ffmpeg -i {frames_path} -c:v libx264 -vf \"fps=25,format=yuv420p\" {result_video}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LV_k_qr41h4I"},"outputs":[],"source":["!cp -r '/content/bbox_clipping/video/bbox_clipping.mp4' '/content/drive/MyDrive/Colab Notebooks/StridedTransformer-Pose3D/demo/video'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcVylQF93Wga"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP0knoU4hsLWGyQ25f2C/eU","collapsed_sections":["Zshu3r5PDr-7"],"mount_file_id":"1MNAc3xk7UiitAEiv9WL6RFYAIfCAcdRK","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0222a5a62fa7476ca2fd5d5be361ac1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20c25c0d9ea742cba04b77200fb48406":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0222a5a62fa7476ca2fd5d5be361ac1d","max":46827520,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a6d63f236bf4ff382608dc3a0019e83","value":46827520}},"2a1a655909cc4a36963c456cecf29f5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cffbaab186f467eb03c8018bd327aad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"555dd134b00840368d6374268c3eef88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ef206b5a92c4bf0a4b263cb4eafb0b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd82cbf2b4344063aaa17661cae0179b","placeholder":"​","style":"IPY_MODEL_a0c6fd41a9b147dfa3fe3e8cb407dd84","value":"100%"}},"73df60f8ae3743718af74ba973061989":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a9a22f52e4945df993939d9a13b9041":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a6d63f236bf4ff382608dc3a0019e83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c02b95270c6439e93fa7f93d2529ffc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea7ce65c188943b68b9222cfd7d0e72e","IPY_MODEL_b8079930999d42149ad0b4d8edb1bd91","IPY_MODEL_a7987ef514fe45369c8a4cc337f806de"],"layout":"IPY_MODEL_7a9a22f52e4945df993939d9a13b9041"}},"a0c6fd41a9b147dfa3fe3e8cb407dd84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a63ea28cb6464b238ae17ba0fed1dc17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7987ef514fe45369c8a4cc337f806de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_555dd134b00840368d6374268c3eef88","placeholder":"​","style":"IPY_MODEL_fa94f3b681204b4f859ddc396bbaec29","value":" 97.8M/97.8M [00:00&lt;00:00, 190MB/s]"}},"a981a179460943c89e37b507d6178b2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad5253e3164745dbb4c4a09584a69c8d","placeholder":"​","style":"IPY_MODEL_de928ca77c6d422f91bc814116763279","value":" 44.7M/44.7M [00:00&lt;00:00, 166MB/s]"}},"ac1cb3213b3a4eaebc51e24840060763":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad5253e3164745dbb4c4a09584a69c8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8079930999d42149ad0b4d8edb1bd91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a1a655909cc4a36963c456cecf29f5d","max":102502400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac1cb3213b3a4eaebc51e24840060763","value":102502400}},"bbc34145149b4b829bc801076a220807":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ef206b5a92c4bf0a4b263cb4eafb0b3","IPY_MODEL_20c25c0d9ea742cba04b77200fb48406","IPY_MODEL_a981a179460943c89e37b507d6178b2b"],"layout":"IPY_MODEL_2cffbaab186f467eb03c8018bd327aad"}},"de928ca77c6d422f91bc814116763279":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea7ce65c188943b68b9222cfd7d0e72e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a63ea28cb6464b238ae17ba0fed1dc17","placeholder":"​","style":"IPY_MODEL_73df60f8ae3743718af74ba973061989","value":"100%"}},"fa94f3b681204b4f859ddc396bbaec29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd82cbf2b4344063aaa17661cae0179b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
